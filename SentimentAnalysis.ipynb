{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57129b27e7608d28",
   "metadata": {},
   "source": [
    "Rule-based"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.464861Z",
     "start_time": "2025-03-13T09:32:28.462453Z"
    }
   },
   "source": [
    "from unittest.mock import sentinel\n",
    "\n",
    "from textblob import TextBlob"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7ef00865b8f6c785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.478348Z",
     "start_time": "2025-03-13T09:32:28.476123Z"
    }
   },
   "source": [
    "sentence_1 = \"i had a great time at the movie it was really funny\"\n",
    "sentence_2 = \"i had a great time at the movie but the parking was terrible\"\n",
    "sentence_3 = \"i had a great time at the movie but the parking wasn't great\"\n",
    "sentence_4 = \"i went to see a movie\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "91830e9b4b7ae36e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.519407Z",
     "start_time": "2025-03-13T09:32:28.485360Z"
    }
   },
   "source": [
    "print(TextBlob(sentence_1).sentiment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.525, subjectivity=0.875)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "4170b75ca82228af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.528868Z",
     "start_time": "2025-03-13T09:32:28.524918Z"
    }
   },
   "source": [
    "print(TextBlob(sentence_2).sentiment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.09999999999999998, subjectivity=0.875)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e566c5035f2a9a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.547400Z",
     "start_time": "2025-03-13T09:32:28.543004Z"
    }
   },
   "source": [
    "print(TextBlob(sentence_3).sentiment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.8, subjectivity=0.75)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "33a9d990251910b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.589557Z",
     "start_time": "2025-03-13T09:32:28.585561Z"
    }
   },
   "source": [
    "print(TextBlob(sentence_4).sentiment)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "4e1a503df7779f18",
   "metadata": {},
   "source": [
    "Vader"
   ]
  },
  {
   "cell_type": "code",
   "id": "450864c517c1804d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.627162Z",
     "start_time": "2025-03-13T09:32:28.621253Z"
    }
   },
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "20b2f046129d6b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.645913Z",
     "start_time": "2025-03-13T09:32:28.637688Z"
    }
   },
   "source": [
    "vader_sid = SentimentIntensityAnalyzer()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "386f4bc29e64bc6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.654327Z",
     "start_time": "2025-03-13T09:32:28.651349Z"
    }
   },
   "source": [
    "print(vader_sid.polarity_scores(sentence_1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.578, 'pos': 0.422, 'compound': 0.807}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "41d7f1055a2c873b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.683942Z",
     "start_time": "2025-03-13T09:32:28.680836Z"
    }
   },
   "source": [
    "print(vader_sid.polarity_scores(sentence_2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.234, 'neu': 0.621, 'pos': 0.144, 'compound': -0.3818}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6388514cd4cd7fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.717275Z",
     "start_time": "2025-03-13T09:32:28.713278Z"
    }
   },
   "source": [
    "print(vader_sid.polarity_scores(sentence_3))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.247, 'neu': 0.611, 'pos': 0.142, 'compound': -0.4387}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "7097ada580d6cd90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:28.740074Z",
     "start_time": "2025-03-13T09:32:28.736075Z"
    }
   },
   "source": [
    "print(vader_sid.polarity_scores(sentence_4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "8b09fc7fbfeaea8b",
   "metadata": {},
   "source": [
    "Pre-trainer transformer models"
   ]
  },
  {
   "cell_type": "code",
   "id": "c26900cce7ea87ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:29.083878Z",
     "start_time": "2025-03-13T09:32:28.755699Z"
    }
   },
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1863\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1862\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1863\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1864\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\importlib\\__init__.py:90\u001B[39m, in \u001B[36mimport_module\u001B[39m\u001B[34m(name, package)\u001B[39m\n\u001B[32m     89\u001B[39m         level += \u001B[32m1\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1387\u001B[39m, in \u001B[36m_gcd_import\u001B[39m\u001B[34m(name, package, level)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1360\u001B[39m, in \u001B[36m_find_and_load\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1331\u001B[39m, in \u001B[36m_find_and_load_unlocked\u001B[39m\u001B[34m(name, import_)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:935\u001B[39m, in \u001B[36m_load_unlocked\u001B[39m\u001B[34m(spec)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:999\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:488\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:26\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature_extraction_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PreTrainedFeatureExtractor\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_processing_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BaseImageProcessor\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mauto\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconfiguration_auto\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoConfig\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\image_processing_utils.py:22\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_processing_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BatchFeature, ImageProcessingMixin\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_transforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m center_crop, normalize, rescale\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChannelDimension, get_image_size\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\image_transforms.py:22\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     23\u001B[39m     ChannelDimension,\n\u001B[32m     24\u001B[39m     ImageInput,\n\u001B[32m     25\u001B[39m     get_channel_dimension_axis,\n\u001B[32m     26\u001B[39m     get_image_size,\n\u001B[32m     27\u001B[39m     infer_channel_dimension_format,\n\u001B[32m     28\u001B[39m )\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\image_utils.py:65\u001B[39m\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torchvision_available():\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m io \u001B[38;5;28;01mas\u001B[39;00m torchvision_io\n\u001B[32m     66\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorchvision\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtransforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InterpolationMode\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\torchvision\\__init__.py:5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmodulefinder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# .extensions) before entering _meta_registrations.\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'torch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pipeline\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:1412\u001B[39m, in \u001B[36m_handle_fromlist\u001B[39m\u001B[34m(module, fromlist, import_, recursive)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1851\u001B[39m, in \u001B[36m_LazyModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1849\u001B[39m     value = Placeholder\n\u001B[32m   1850\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._class_to_module.keys():\n\u001B[32m-> \u001B[39m\u001B[32m1851\u001B[39m     module = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1852\u001B[39m     value = \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[32m   1853\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._modules:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1865\u001B[39m, in \u001B[36m_LazyModule._get_module\u001B[39m\u001B[34m(self, module_name)\u001B[39m\n\u001B[32m   1863\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib.import_module(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m + module_name, \u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m)\n\u001B[32m   1864\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m-> \u001B[39m\u001B[32m1865\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1866\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m because of the following error (look up to see its\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1867\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   1868\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nNo module named 'torch'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "df1ee3de708c9e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:29.087103500Z",
     "start_time": "2025-03-12T22:07:34.820052Z"
    }
   },
   "source": "sentinel.pipeline = pipeline(\"sentiment-analysis\", model='finiteautomata/bertweet-base-sentiment-analysis')",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[65]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m sentinel.pipeline = \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43msentiment-analysis\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mfiniteautomata/bertweet-base-sentiment-analysis\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:940\u001B[39m, in \u001B[36mpipeline\u001B[39m\u001B[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[39m\n\u001B[32m    938\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m framework \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    939\u001B[39m     model_classes = {\u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m: targeted_task[\u001B[33m\"\u001B[39m\u001B[33mtf\u001B[39m\u001B[33m\"\u001B[39m], \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m: targeted_task[\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m]}\n\u001B[32m--> \u001B[39m\u001B[32m940\u001B[39m     framework, model = \u001B[43minfer_framework_load_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_classes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mframework\u001B[49m\u001B[43m=\u001B[49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    950\u001B[39m model_config = model.config\n\u001B[32m    951\u001B[39m hub_kwargs[\u001B[33m\"\u001B[39m\u001B[33m_commit_hash\u001B[39m\u001B[33m\"\u001B[39m] = model.config._commit_hash\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Dev\\Training projects\\AI\\NLP365\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:241\u001B[39m, in \u001B[36minfer_framework_load_model\u001B[39m\u001B[34m(model, config, model_classes, task, framework, **model_kwargs)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    216\u001B[39m \u001B[33;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001B[39;00m\n\u001B[32m    217\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    238\u001B[39m \u001B[33;03m    `Tuple`: A tuple framework, model.\u001B[39;00m\n\u001B[32m    239\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    240\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tf_available() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_available():\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    242\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    243\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    244\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mTo install PyTorch, read the instructions at https://pytorch.org/.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    245\u001B[39m     )\n\u001B[32m    246\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    247\u001B[39m     model_kwargs[\u001B[33m\"\u001B[39m\u001B[33m_from_pipeline\u001B[39m\u001B[33m\"\u001B[39m] = task\n",
      "\u001B[31mRuntimeError\u001B[39m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "b08ba0a9-2e9e-4a51-9cc8-41ee0d927b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:32:29.100308300Z",
     "start_time": "2025-03-12T22:07:42.375445Z"
    }
   },
   "source": [
    "print(sentence_1)\n",
    "sentinel.pipeline(sentence_1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i had a great time at the movie it was really funny\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_SentinelObject' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[66]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28mprint\u001B[39m(sentence_1)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43msentinel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence_1\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: '_SentinelObject' object is not callable"
     ]
    }
   ],
   "execution_count": 66
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
