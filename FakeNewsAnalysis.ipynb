{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import Data",
   "id": "f8d0e1cf01e4fa97"
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# set plot options\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "default_plot_colour = \"#00bfbf\""
   ],
   "id": "8868b75038964d98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv(\"fake_news_data.csv\")",
   "id": "c0b31b2c0101a830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.head()",
   "id": "fdbca8870ae93ca3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# plot number of fake and factual articles\n",
    "data['fake_or_factual'].value_counts().plot(kind='bar', color=default_plot_colour)\n",
    "plt.title('Count of Article Classification')\n",
    "plt.ylabel('# of Articles')\n",
    "plt.xlabel('Classification')"
   ],
   "id": "64b3800898eb964d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Packages for cleaing and analysis",
   "id": "aa1b6c00b8392842"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy import tokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import LsiModel, TfidfModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "id": "fc05dc16c68a9399",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "POS Tagging",
   "id": "dab90d4419f4185f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load('en_core_web_sm')",
   "id": "b3199fb9c63c6987",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# split data by fake and factual news\n",
    "fake_news = data[data['fake_or_factual'] == \"Fake News\"]\n",
    "fact_news = data[data['fake_or_factual'] == \"Factual News\"]"
   ],
   "id": "2dd2eb3ed44944a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create spacey documents - use pipe for dataframe\n",
    "fake_spaceydocs = list(nlp.pipe(fake_news['text']))\n",
    "fact_spaceydocs = list(nlp.pipe(fact_news['text']))"
   ],
   "id": "3e665979974407b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create function to extract tags for each document in our data\n",
    "def extract_token_tags(doc:spacy.tokens.doc.Doc):\n",
    "    return [(i.text, i.ent_type_, i.pos_) for i in doc]"
   ],
   "id": "cec9c473ea2d5cea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tag fake dataset\n",
    "fake_tagsdf = []\n",
    "columns = [\"token\", \"ner_tag\", \"pos_tag\"]\n",
    "\n",
    "for ix, doc in enumerate(fake_spaceydocs):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    fake_tagsdf.append(tags)\n",
    "\n",
    "fake_tagsdf = pd.concat(fake_tagsdf)\n",
    "\n",
    "# tag factual dataset\n",
    "fact_tagsdf = []\n",
    "\n",
    "for ix, doc in enumerate(fact_spaceydocs):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags = pd.DataFrame(tags)\n",
    "    tags.columns = columns\n",
    "    fact_tagsdf.append(tags)\n",
    "\n",
    "fact_tagsdf = pd.concat(fact_tagsdf)"
   ],
   "id": "4d5971266667b8e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# token frequency count (fake)\n",
    "pos_counts_fake = fake_tagsdf.groupby(['token','pos_tag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "pos_counts_fake.head(10)"
   ],
   "id": "4a6c96928d8ea714"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# token frequency count (fact)\n",
    "pos_counts_fact = fact_tagsdf.groupby(['token','pos_tag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "pos_counts_fact.head(10)"
   ],
   "id": "55314f8857942549"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# frequencies of pos tags\n",
    "pos_counts_fake.groupby(['pos_tag'])['token'].count().sort_values(ascending=False).head(10)"
   ],
   "id": "eadad4ff329d8a7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pos_counts_fact.groupby(['pos_tag'])['token'].count().sort_values(ascending=False).head(10)",
   "id": "4d36802e73977766"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dive into differences in nouns\n",
    "pos_counts_fake[pos_counts_fake.pos_tag == \"NOUN\"][0:15]"
   ],
   "id": "172e9482da0138b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
